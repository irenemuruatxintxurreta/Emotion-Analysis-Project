{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Rlhs0tWYQOU"
   },
   "source": [
    "We have already seen strong in-domain performance on GoEmotions, but real users don’t write Reddit comments—they write tweets, product reviews, support tickets, and so on. By running the three models (SVM, BERT, RoBERTa) on the Hugging-Face “emotion” tweets corpus, we are performing a domain-shift evaluation: we are asking, “How well does my GoEmotions-trained classifier generalize to text written in a completely different style and genre?” That gap between in-domain and out-of-domain accuracy is critical for understanding whether the model is truly robust or whether it has merely memorized patterns specific to Reddit.\n",
    "\n",
    "Using the small, human-labeled Emotion dataset lets us do this with no extra annotation effort— we already have gold labels for sadness, joy, love, anger, fear, surprise, and neutral, all of which map directly into the GoEmotions taxonomy. By computing Top-1 accuracy, we  see how often the model’s very best guess aligns with human judgment. By computing Top-3 recall, we measure whether the true emotion at least appears among the model’s top suggestions—an especially important metric in multi-label or recommendation-style scenarios, where surfacing the right answer in the top few options can be good enough for a downstream application.\n",
    "\n",
    "Comparing the three approaches under this evaluation framework accomplishes several things at once:\n",
    "\n",
    "Quantifies Generalization – We will see whether the clear RoBERTa advantage on GoEmotions holds when dealing with tweets, or if the simpler SVM or smaller BERT models close the gap.\n",
    "\n",
    "Reveals Failure Modes – A big drop in Top-1 accuracy but a modest Top-3 recall can tell us if our model still “understands” the emotion but struggles to rank it first.\n",
    "\n",
    "Guides Next Steps – If all models perform poorly out-of-domain, that’s a strong signal that we need domain-adaptive pretraining on tweet/review text, or at least some in-domain fine-tuning to bring performance back up.\n",
    "\n",
    "Ultimately, this real-world evaluation gives us the evidence to say, “Here’s how my models behave when faced with new, unseen text—this is their true performance in the wild,” rather than just “here’s how they did on Reddit comments.” That kind of insight is what turns a proof-of-concept into a production-ready solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Gmw8EH9YGIG",
    "outputId": "a19fce56-8509-43c2-e23b-567e5c094a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers scikit-learn joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sj6jYp1Uty9y",
    "outputId": "e908fa93-42f3-4d2e-e628-95c911fa76e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade fsspec datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nya41L1GcJ3z",
    "outputId": "731e96b7-2e71-482a-e13f-4a8eb0c35fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362,
     "referenced_widgets": [
      "99e3472147584d2ead6db20209e9c198",
      "d2176b4ddd7e44f69a2fb0d5e69d0fe9",
      "e52080022a90451b9d8b890470fed66b",
      "7897ed8b79f54a13bbdc58618e306487",
      "ec1d91d91f59443ea501a96b2b590787",
      "4319688883bb4a50aeea4fe6f055725b",
      "33d824d083cb43de8f79d6ea3e1cf5b0",
      "7695d790e6e546e68c9e795190c391f4",
      "a261d2ce627e439db26698d5993e2470",
      "bd30cf4705e0445a96f27755d8309eba",
      "0ad2e18b0cde49958f0e0f8fb66de32e",
      "9ec4c68fefe34099a79433fcc10a1d26",
      "ebefeb5b5d48479385e18f89b04d104e",
      "e99034754b4a4161a7421bf5335c6f15",
      "a99727f882f54ba7999ff4398b612005",
      "c8e4c1db050144718987b6f5140434f7",
      "109436024a344886a80b8972de2cf232",
      "fdc53c4716384d2c8bd5c044cb304d8f",
      "9582e2e533394bb48ce4881a7efe066b",
      "724fa36fbc9744faac66abc9d3d92235",
      "c315eeb8f6dd49369e47799d9d41df98",
      "f983e79c77b548af93c3afd9dea607b5",
      "e69b5f6da877416bb3a2feea5e8a7088",
      "2f341ea107e6467a9271141c307dd4e5",
      "a05e60ed7344464d860ca38a422d4938",
      "435d630d9a5d492eac6e53f09b08fadb",
      "39c1c10ff57b4b19b1f4236d5ca69921",
      "d2bc0a8f8fde4f2bad35bbc8ba2663f1",
      "7b21165cb7d84237ae760f30532c96c9",
      "73b49fac375d48088a737e5b5d2c1c69",
      "462ffa03463c4ad5aef7ffcbf92f8f5d",
      "ad689b227fbd49cbabcb0c47e698f818",
      "90b7cd827c0c4c09a3b9e09c135c327f",
      "994aa99211764380a90538958630956c",
      "d2846ce516c64e90a867fcc37021354c",
      "7c35a70fa161427bb5f68778750cb02f",
      "a26e9b81642248e5826db4b491cc9919",
      "003685d4317947879be9445aa6e642e8",
      "80bad1348bba4139ae57f9e9ca2d81d3",
      "38a75b6ee0484be0940433ea8f210a61",
      "65cdc81dc4aa4eaf8da0f0e265950a55",
      "0cef55f7a2c64e498528050f2ab217a2",
      "51b72daf3d414d3f856fcd726863511b",
      "aa0a89b0a5ad414aadff1567fbeab56c",
      "5347d94149b1442f8c7b78a75b61e3f2",
      "51e9f40f17034932b419d481587ba53f",
      "e9c469b84ce148da84b3eff5c4fd8718",
      "96dc6722852b4e5d816473c5a3a4a493",
      "9780bd9453bb4429a389fbe6bc1834f4",
      "0f38afa42f594b38aec50a6026441c2d",
      "3d5177ad25c04830bce393cd137e7e6e",
      "4a5b82fcf2074d00945571bb3551018a",
      "f316cf0c002744ba895801ff3be453c6",
      "1b2ec5e3cce849a892e426352940d1f8",
      "58df06093e224f368fed82728530243c",
      "a9097953ad314e7ca53b2dc5f4de023f",
      "8d3e2282bed94d7ea95f588c04d82082",
      "731742f4d6af4a85b903a07f216217a7",
      "d58b981440c84a25922b2ad8bde729bb",
      "051b9a00e2634a4b98dc0920f41d1af1",
      "93abe128fa9e43cd83a814aa3c8af976",
      "5cbc79be0ed74410b1dae57e8c1d649b",
      "07d34b531561413089b183789b9c52df",
      "bdff248d0c314c7e98f79c2c0a4c5e59",
      "00d7c42e7b6b4e72820fb14d3b81cee1",
      "810baa1f17d04146bf9be0c7023084f1",
      "874eadb1da2c44448109ce3e6c23fbd7",
      "8ffcd555aca94bf1b14a8ccc74304cde",
      "50e5469b6fd646a088baaf66d7e8975c",
      "57ff3a20714e40808b8d7751c10924dc",
      "2a0c32fa1d9f45f2b4c80b847b0249d7",
      "80fd4ca6937b4a59b040f1d50119d4c3",
      "98b56fe43e494b728b4f061492190436",
      "2d97cfba2f2947048c8609f1b149b2ba",
      "089210633ee84d0cacb9a511d3abd39b",
      "7194c265c8ef4a96977297a2baa38305",
      "40685ece84b542e8b72528860f31abef"
     ]
    },
    "id": "rDeaxKlUcL6_",
    "outputId": "849f8717-5c24-4bec-8abd-e95bd3d6c263"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e3472147584d2ead6db20209e9c198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec4c68fefe34099a79433fcc10a1d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/2.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69b5f6da877416bb3a2feea5e8a7088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/350k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994aa99211764380a90538958630956c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/347k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5347d94149b1442f8c7b78a75b61e3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9097953ad314e7ca53b2dc5f4de023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874eadb1da2c44448109ce3e6c23fbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load just to grab the label names:\n",
    "go = load_dataset(\"go_emotions\")\n",
    "emotion_names = go[\"train\"].features[\"labels\"].feature.names\n",
    "print(emotion_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cP_tvZ75cSTY"
   },
   "source": [
    "## Load & Build The Three Inference Pipelines#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rki9ZiPvcaTL"
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d-yabmBgce_D"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "vec_path = \"/content/drive/MyDrive/svm_emotion_baseline/tfidf_vectorizer.joblib\"\n",
    "mdl_path = \"/content/drive/MyDrive/svm_emotion_baseline/svm_model.joblib\"\n",
    "lb_path  = \"/content/drive/MyDrive/svm_emotion_baseline/label_binarizer.joblib\"\n",
    "\n",
    "vectorizer = joblib.load(vec_path)\n",
    "svm_model   = joblib.load(mdl_path)\n",
    "mlb         = joblib.load(lb_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GP8CTrYcgPv"
   },
   "source": [
    "### BERT & ROBERTA     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AmLH7zEcjKK",
    "outputId": "cee092f7-186f-4b64-dace-4886f6e98bac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "def make_multi_label_pipeline(model_folder):\n",
    "    tok = AutoTokenizer.from_pretrained(model_folder)\n",
    "    mdl = AutoModelForSequenceClassification.from_pretrained(model_folder)\n",
    "    return pipeline(\n",
    "        \"text-classification\",\n",
    "        model=mdl,\n",
    "        tokenizer=tok,\n",
    "        function_to_apply=\"sigmoid\",\n",
    "        top_k=None       # return every label’s probability\n",
    "    )\n",
    "\n",
    "\n",
    "pipe_roberta = make_multi_label_pipeline(\"/content/drive/MyDrive/emotion_model\")\n",
    "pipe_bert    = make_multi_label_pipeline(\"/content/drive/MyDrive/BERT_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tavSdI5Tc1he"
   },
   "source": [
    "## Load the Out-of-Domain “Emotion” Tweets Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "c1d11e9b92c14fa39b37b9047227f777",
      "336fe95a112c41ab8d4c81e81f5cbb37",
      "4b3d51691ca84ca8be0a2b5dae494452",
      "760f99718cd040bb9f0ceedd04fd7539",
      "89b1df1e65144d31903ccd1597cfa13e",
      "60f5e4dcecbd47079f0d953fefaf61f7",
      "e3fa3f50c58a45a1ab1a659231a1c56f",
      "d3f551a0e44d4262822bdb0a0924b9b1",
      "1e0e1f600d964ccbb98fb88cb16a4a4b",
      "38644e8a8bca408dac3164a565deef5d",
      "a6fe6f49b9b04dd19b562d85a0616b13",
      "c4504091396e40db861636628dd1f9fe",
      "62954ce9e0a2410ca748259c1052b0b1",
      "3ebb7f9986874319b735e8820db951f2",
      "c87f805b126b48b99c27fd55c70d4746",
      "9a9c9817d533473884b40c39a9c595c3",
      "2f3e185ba49e4533b4afb9f8a8de1e3e",
      "35f77f12c97d4abb89102bb6e7cd50ad",
      "3c242780c14544b09ed9e9bd3ccd499f",
      "8da7765980c9491a9287851321f4b16c",
      "305b98450ead4348b9527ba577bf3f75",
      "5f84be13424b49a1a3884db83e0be791",
      "c15d6c536460445b93cf8c05bd2aeadd",
      "eade5d29a6c64b8daa79068552cc0d38",
      "32845b302e254e9583248e899792ff4a",
      "a9eac4c1ff6e454aa06db324b70bf90c",
      "3c108aca6cc24b8597752999256f1578",
      "2b5c27545c5246dc891209cad339b133",
      "eae8f2e06df94de5864659f412ea221e",
      "783dff4de9154d3e8c887a27b636d177",
      "7c12b1a861204ae5b6e912d72af29942",
      "78e9c76079434bcaa78303bbe2fa441e",
      "c64d447a5811492fb6b35e1d8ba4886b",
      "72af500e1dad46c88e722ba0aa4b013b",
      "7892aad487f6429e9e739eff24aa2e78",
      "f5db7f64231545f5b4b7f3afc7a4f51b",
      "41e6db969f54472baa82fa810547db9e",
      "db2a8a21b57a47d990eaa2c408d40803",
      "542f5a82bc2b4a7195ccf20ffcab55a9",
      "e48cece03edb4b6da47a05623f249530",
      "e03aac1d65224d87a13f474483cdeae5",
      "64c88c920ee642f38f517907d83fafe1",
      "cf9502cd7f5843f9b647d2450ac0b53d",
      "94fc872a0359458a86fb4396edc91331",
      "9357c1c66a014c168070a300f3ba7dfc",
      "ed3aa43ae804460bba19d2dfa3c617c7",
      "b355c79ba6b04076a82abf15d7666a6b",
      "0b408159b1c7488b9e269c758448dde9",
      "c4da238947bc4445b332116e20156525",
      "5d62a82299fa42de8b14f977d8a235e8",
      "d7326303f0e54c11b4bd15774c815ed9",
      "45dd0a03b82740bf95e005704e562680",
      "8eca344ec7be4c20ad509e7ca1a54eb5",
      "7e692d7bd87c4d37937b9aedd57556ac",
      "54f91e1fb4dd446d82ad2d44c8f4bb29",
      "cf715a1bda77425b8036040265b960a3",
      "64415f73171547c79ec741aa96cf2936",
      "80b6938e79f44de899223551755f98be",
      "3c07c97e4e704fffa642a2a0662093ca",
      "294b975adfa04ee4a3855001903ccd8f",
      "a4f282184bba40c2be1b632b80aa2325",
      "ffb18361590c4066b9ea2871e2c07192",
      "3adfb3e401064b20a5c0c95009a0fcef",
      "64a25ab757c34bdc98cd528da9d13e33",
      "9826c54d69df44a48a9a466b3f351061",
      "853ee83c8dd54f3d9efd504c86b4ab14",
      "671eeb5a0a8b41c5ade502b345bd5cc6",
      "3b0050e09e0d48b8b941c26a10bc7bc4",
      "5a0ead9888694f869e4ed2fa7412f477",
      "bbf6f1f10c604f5eae441f719c8e26da",
      "0aeac38992624749900a12922d134675",
      "4a5c7c69ca3842d099eb967ac40b3e5f",
      "b6fb2c70a27848e1b786d34adfdeccf0",
      "6565df41514746c2912cf001dfb89b30",
      "b4528a40fdec4e8fabd2ef0686012058",
      "f0b6f629a3c84968b8493f8ab5a9bcf3",
      "e91797a3512144f080258c9bf2d8c4d0"
     ]
    },
    "id": "fDYx0Wp8c0oC",
    "outputId": "9805806b-7ef9-4e79-af94-2861536da8f1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d11e9b92c14fa39b37b9047227f777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4504091396e40db861636628dd1f9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15d6c536460445b93cf8c05bd2aeadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72af500e1dad46c88e722ba0aa4b013b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/129k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9357c1c66a014c168070a300f3ba7dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf715a1bda77425b8036040265b960a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671eeb5a0a8b41c5ade502b345bd5cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF emotion labels: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emod = load_dataset(\"emotion\")\n",
    "texts = emod[\"test\"][\"text\"]       # ~2,000 tweets\n",
    "gold  = emod[\"test\"][\"label\"]      # ints 0..6\n",
    "hf_names = emod[\"train\"].features[\"label\"].names\n",
    "print(\"HF emotion labels:\", hf_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8StrXSwTc8PH"
   },
   "source": [
    "## Map HF-Emotion Labels → Go-Emotions Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8H2JyFoVc8aS",
    "outputId": "f7bbf982-643b-4be9-e324-55974e35ca3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping HF→Go: {0: 25, 1: 17, 2: 18, 3: 2, 4: 14, 5: 26}\n"
     ]
    }
   ],
   "source": [
    "# Build name → GoEmotions index\n",
    "go2idx = {name:i for i,name in enumerate(emotion_names)}\n",
    "\n",
    "# HF index (0–6) → GoEmotions index (0–27)\n",
    "hf2go = {hf_i: go2idx[name] for hf_i,name in enumerate(hf_names)}\n",
    "\n",
    "print(\"Mapping HF→Go:\", hf2go)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXuGZDnJdI6H"
   },
   "source": [
    "## Run Inference & Compute Top-1 / Top-3 Metrics\n",
    "### Loop over every tweet, get the sorted predictions from each model, and check:\n",
    "\n",
    "Top-1 Accuracy: was the model’s #1 guess equal to the gold emotion?\n",
    "\n",
    "Top-3 Recall: did the gold emotion appear anywhere in the model’s top-3 guesses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlYgII3XltnZ"
   },
   "source": [
    "Re-define preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOvfMfDzmP-h",
    "outputId": "86451b78-09c1-443a-85d7-4ee7fae40f27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')      # the standard tokenizer\n",
    "nltk.download('punkt_tab')  # the extra one NLTK is looking for\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "f0dhnIZrl2Pa"
   },
   "outputs": [],
   "source": [
    "# ──────────────── Re-define your SVM preprocessing ────────────────\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1) lowercase\n",
    "    text = text.lower()\n",
    "    # 2) remove everything except letters & spaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # 3) tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # 4) drop stopwords\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    # 5) re-join\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsrQAJzTdLRh",
    "outputId": "2ef886ad-8688-4439-fbcb-34936f91eb00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM      → Top-1 Acc: 0.088, Top-3 Recall: 0.212\n",
      "BERT     → Top-1 Acc: 0.198, Top-3 Recall: 0.384\n",
      "ROBERTA  → Top-1 Acc: 0.213, Top-3 Recall: 0.403\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = len(texts)\n",
    "results = {\n",
    "    \"svm_top1\":   np.zeros(n, dtype=bool),\n",
    "    \"svm_top3\":   np.zeros(n, dtype=bool),\n",
    "    \"bert_top1\":  np.zeros(n, dtype=bool),\n",
    "    \"bert_top3\":  np.zeros(n, dtype=bool),\n",
    "    \"roberta_top1\": np.zeros(n, dtype=bool),\n",
    "    \"roberta_top3\": np.zeros(n, dtype=bool),\n",
    "}\n",
    "\n",
    "for idx, (txt, hf_label) in enumerate(zip(texts, gold)):\n",
    "    true_go = hf2go[hf_label]\n",
    "\n",
    "    # — SVM (unchanged) —\n",
    "    proc        = preprocess_text(txt)\n",
    "    feats       = vectorizer.transform([proc])\n",
    "    svm_scores  = svm_model.decision_function(feats)[0]\n",
    "    svm_labels  = np.argsort(svm_scores)[::-1]   # these _are_ label IDs\n",
    "    results[\"svm_top1\"][idx] = (svm_labels[0] == true_go)\n",
    "    results[\"svm_top3\"][idx] = (true_go in svm_labels[:3])\n",
    "\n",
    "    # — BERT & RoBERTa (fixed) —\n",
    "    for name, pipe in [(\"bert\", pipe_bert), (\"roberta\", pipe_roberta)]:\n",
    "        out = pipe([txt])[0]\n",
    "        pred_label_ids = [int(d[\"label\"].split(\"_\")[1]) for d in out]\n",
    "        results[f\"{name}_top1\"][idx] = (pred_label_ids[0] == true_go)\n",
    "        results[f\"{name}_top3\"][idx] = (true_go in pred_label_ids[:3])\n",
    "\n",
    "\n",
    "# 8. Summarize\n",
    "for model in [\"svm\", \"bert\", \"roberta\"]:\n",
    "    top1 = results[f\"{model}_top1\"].mean()\n",
    "    top3 = results[f\"{model}_top3\"].mean()\n",
    "    print(f\"{model.upper():8} → Top-1 Acc: {top1:.3f}, Top-3 Recall: {top3:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUul5MS8lHQ-"
   },
   "source": [
    "## Interpret the Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWwafm8qIqIj"
   },
   "source": [
    "Interpretation of Domain-Shift Results\n",
    "SVM → BERT → RoBERTa still holds in the new setting—transformers outperform the TF-IDF baseline—but all models exhibit a dramatic drop in Top-1 and Top-3 metrics when moving from Reddit comments (Go-Emotions) to tweets (HF Emotion).\n",
    "\n",
    "Domain Mismatch Drives Low Scores\n",
    "\n",
    "Style & Length: Tweets are typically shorter, use non-standard spellings, hashtags, and emoji, whereas Go-Emotions examples are longer, more formal Reddit sentences.\n",
    "\n",
    "Vocabulary & Slang: Emotion expressions on Twitter often involve slang (“lol,” “smh”), emoticons, or culture-specific references that the models never saw in training.\n",
    "\n",
    "As a result, even RoBERTa “knows” the right emotion only ~40 % of the time in its top-3—roughly on par with picking three labels at random—because it must generalize across vastly different text genres.\n",
    "\n",
    "Why This Is Expected\n",
    "\n",
    "Overfitting to In-Domain Patterns: The fine-tuned models learn to pick up on distribution-specific cues (e.g. punctuation patterns, phrase structures) that don’t carry over to tweets.\n",
    "\n",
    "No In-Domain Examples: Without seeing actual tweets during either pretraining or fine-tuning, it’s normal that performance plummets—transformers excel when their training data matches the test distribution.\n",
    "\n",
    "Random-Guess Baseline Comparison: A random Top-3 guess on 7 classes yields ~43 % recall; RoBERTa’s ~40 % shows it’s only marginally better than chance in this zero-shot scenario.\n",
    "\n",
    "Key Takeaway\n",
    "\n",
    "Low absolute numbers are not a “bug” but a clear signal of domain shift.\n",
    "\n",
    "These results underscore the necessity of domain-adaptive steps—whether further pretraining on unlabeled tweets, or fine-tuning on even a small labeled tweet set—to bridge the gap between the research data and real-world text.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
